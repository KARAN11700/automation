{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c38d40d-d5e9-46d9-a6d6-3709de0950ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import feedparser\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "#from PIL import Image\n",
    "#from io import BytesIO\n",
    "import openai  \n",
    "import json\n",
    "import os\n",
    "from configparser import ConfigParser\n",
    "\n",
    "config = ConfigParser()\n",
    "config.read(\"config1.ini\")\n",
    "\n",
    "OPENAI_API_KEY = config.get(\"Keys\",\"OPENAI_API_KEY_1\")\n",
    "BITLY_API_KEY =  config.get(\"Keys\",\"BITLY_API_KEY_1\")\n",
    "WEBSITE_API_URL = config.get(\"Keys\",\"WEBSITE_API_URL_1\")\n",
    "WEBSITE_API_KEY = config.get(\"Keys\",\"WEBSITE_API_KEY_1\")\n",
    "\n",
    "\n",
    "def fetch_rss_feed(url):\n",
    "    feed = feedparser.parse(url)\n",
    "    return feed.entries\n",
    "\n",
    "rss_feed_url = \"https://news.google.com/rss/search?q=Business+News&hl=en-US&gl=US&ceid=US:en\"\n",
    "articles = fetch_rss_feed(rss_feed_url)\n",
    "\n",
    "for article in articles:\n",
    "    print(f\"Title: {article.title}\")\n",
    "    print(f\"Link: {article.link}\")\n",
    "    print(f\"Published: {article.published}\\n\")\n",
    "\n",
    "def extract_article_details(article_url):\n",
    "    response = requests.get(article_url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    # Extract the title of the article\n",
    "    title = soup.find('title').get_text() if soup.find('title') else \"No title found\"\n",
    "    \n",
    "    # Extract the first 3 paragraphs of the article\n",
    "    content = \" \".join([p.get_text() for p in soup.find_all('p')[:3]])\n",
    "    \n",
    "    return title, content\n",
    "\n",
    "article_url = \"https://edition.cnn.com/2025/01/02/media/trump-new-orleans-attack-migrants-fox-news/index.html\"\n",
    "\n",
    "title, content = extract_article_details(article_url)\n",
    "\n",
    "print(\"Title:\", title)\n",
    "print(\"Content:\", content)\n",
    "\n",
    "def generate_caption(content):\n",
    "    openai.api_key = OPENAI_API_KEY\n",
    "    prompt = f\"Write a 2-3 sentence caption for the following content:\\n\\n{content}\"\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"text-davinci-003\", #use 'gpt-4'  model also\n",
    "        prompt=prompt,\n",
    "        max_tokens=60\n",
    "    )\n",
    "    return response['choices'][0]['text'].strip()\n",
    ")\n",
    "print(response)\n",
    "\n",
    "config = ConfigParser()\n",
    "config.read(\"config1.ini\")\n",
    "OPENAI_API_KEY = config.get(\"Keys\", \"OPENAI_API_KEY_1\")\n",
    "\n",
    "\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "prompt= \"content\"\n",
    "try:\n",
    "    response = openai.Image.create(\n",
    "        prompt=\"content\",\n",
    "        n=1,\n",
    "        size=\"1024x1024\"\n",
    "    )\n",
    "    image_url = response['data'][0]['url']\n",
    "    print(f\"Generated Image URL: {image_url}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "def upload_to_website(caption, image_url, WEBSITE_API_URL, WEBSITE_API_KEY):\n",
    "    headers = {\"Authorization\": f\"Bearer {WEBSITE_API_KEY}\"}\n",
    "    payload = {\"caption\": caption, \"image_url\": image_url}\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(WEBSITE_API_URL, headers=headers, json=payload)\n",
    "        response.raise_for_status()  \n",
    "        return response.status_code, response.json()  \n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error uploading to website: {e}\")\n",
    "        return None, str(e)\n",
    "\n",
    "WEBSITE_API_URL = \"https://example.com/api/upload\"\n",
    "WEBSITE_API_KEY = \"your-api-key-here\"\n",
    "\n",
    "#caption = \"A serene landscape with mountains and a flowing river.\"\n",
    "#image_url = \"https://example.com/path/to/image.jpg\"\n",
    "\n",
    "status_code, response_content = upload_to_website(caption, image_url, WEBSITE_API_URL, WEBSITE_API_KEY)\n",
    "\n",
    "if status_code:\n",
    "    print(f\"Upload successful! Status Code: {status_code}\")\n",
    "    print(f\"Response Content: {response_content}\")\n",
    "else:\n",
    "    print(\"Failed to upload.\")\n",
    "\n",
    "def main():\n",
    "    rss_feed_url = https://news.google.com/rss/search?q=Business+News&hl=en-US&gl=US&ceid=US:en\" \n",
    "    articles = fetch_rss_feed(rss_feed_url)\n",
    "    \n",
    "    for article in articles[:1]: \n",
    "        article_url = article.link\n",
    "        title, content = extract_article_details(article_url)\n",
    "        \n",
    "        caption = generate_caption(content)\n",
    "        #short_url = shorten_url(article_url)\n",
    "        #full_caption = f\"{caption} Read more: {short_url}\"\n",
    "        \n",
    "        image_url = generate_image(content)\n",
    "        status_code = upload_to_website(caption, image_url)\n",
    "        \n",
    "        if status_code == 200:\n",
    "            print(f\"Successfully uploaded article: {title}\")\n",
    "        else:\n",
    "            print(f\"Failed to upload article: {title}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f53b6a5-ffb2-4082-a027-648648df4a38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
