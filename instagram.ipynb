{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452303cf-9b8b-4d0b-bd48-01fe25e4ac17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import feedparser\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "#from PIL import Image\n",
    "#from io import BytesIO\n",
    "import openai  \n",
    "import json\n",
    "import os\n",
    "from configparser import ConfigParser\n",
    "\n",
    "config = ConfigParser()\n",
    "config.read(\"config2.ini\")\n",
    "\n",
    "OPENAI_API_KEY = config.get(\"Keys\",\"OPENAI_API_KEY_1\")\n",
    "access_token = config.get(\"keys\", \"access_token_1\")\n",
    "\n",
    "\n",
    "def fetch_rss_feed(url):\n",
    "    feed = feedparser.parse(url)\n",
    "    return feed.entries\n",
    "\n",
    "rss_feed_url = \"https://news.google.com/rss/search?q=Business+News&hl=en-US&gl=US&ceid=US:en\"\n",
    "articles = fetch_rss_feed(rss_feed_url)\n",
    "\n",
    "for article in articles:\n",
    "    print(f\"Title: {article.title}\")\n",
    "    print(f\"Link: {article.link}\")\n",
    "    print(f\"Published: {article.published}\\n\")\n",
    "\n",
    "def extract_article_details(article_url):\n",
    "    response = requests.get(article_url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    # Extract the title of the article\n",
    "    title = soup.find('title').get_text() if soup.find('title') else \"No title found\"\n",
    "    \n",
    "    # Extract the first 3 paragraphs of the article\n",
    "    content = \" \".join([p.get_text() for p in soup.find_all('p')[:3]])\n",
    "    \n",
    "    return title, content\n",
    "\n",
    "article_url = \"https://edition.cnn.com/2025/01/02/media/trump-new-orleans-attack-migrants-fox-news/index.html\"\n",
    "\n",
    "title, content = extract_article_details(article_url)\n",
    "\n",
    "print(\"Title:\", title)\n",
    "print(\"Content:\", content)\n",
    "\n",
    "def generate_caption(content):\n",
    "    openai.api_key = OPENAI_API_KEY\n",
    "    prompt = f\"Write a 2-3 sentence caption for the following content:\\n\\n{content}\"\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"text-davinci-003\", #use 'gpt-4'  model also\n",
    "        prompt=prompt,\n",
    "        max_tokens=60\n",
    "    )\n",
    "    return response['choices'][0]['text'].strip()\n",
    ")\n",
    "#print(response)\n",
    "\n",
    "config = ConfigParser()\n",
    "config.read(\"config1.ini\")\n",
    "OPENAI_API_KEY = config.get(\"Keys\", \"OPENAI_API_KEY_1\")\n",
    "\n",
    "\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "prompt= \"content\"\n",
    "try:\n",
    "    response = openai.Image.create(\n",
    "        prompt=\"content\",\n",
    "        n=1,\n",
    "        size=\"1024x1024\"\n",
    "    )\n",
    "    image_url = response['data'][0]['url']\n",
    "    print(f\"Generated Image URL: {image_url}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "import requests\n",
    "\n",
    "def upload_to_instagram(caption, image_url, access_token, instagram_account_id):\n",
    "    upload_url = f\"https://graph.facebook.com/v15.0/{instagram_account_id}/media\"\n",
    "    \n",
    "    payload = {\n",
    "        \"image_url\": image_url,\n",
    "        \"caption\": caption,\n",
    "        \"access_token\": access_token\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(upload_url, data=payload)\n",
    "        response.raise_for_status()\n",
    "        media_id = response.json()[\"id\"]\n",
    "        publish_url = f\"https://graph.facebook.com/v15.0/{instagram_account_id}/media_publish\"\n",
    "        publish_payload = {\n",
    "            \"creation_id\": media_id,\n",
    "            \"access_token\": access_token\n",
    "        }\n",
    "        \n",
    "        publish_response = requests.post(publish_url, data=publish_payload)\n",
    "        publish_response.raise_for_status()\n",
    "        return \"Image uploaded successfully\"\n",
    "    \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error uploading to Instagram: {e}\")\n",
    "        return f\"Error uploading to Instagram: {e}\"\n",
    "\n",
    "def main():\n",
    "    rss_feed_url = https://news.google.com/rss/search?q=Business+News&hl=en-US&gl=US&ceid=US:en\" \n",
    "    articles = fetch_rss_feed(rss_feed_url)\n",
    "    \n",
    "    for article in articles[:1]: \n",
    "        article_url = article.link\n",
    "        title, content = extract_article_details(article_url)\n",
    "        \n",
    "        caption = generate_caption(content)\n",
    "        #short_url = shorten_url(article_url)\n",
    "        #full_caption = f\"{caption} Read more: {short_url}\"\n",
    "        \n",
    "        image_url = generate_image(content)\n",
    "        status_code = upload_to_instagram(caption, image_url)\n",
    "        \n",
    "        if status_code == 200:\n",
    "            print(f\"Successfully uploaded article: {title}\")\n",
    "        else:\n",
    "            print(f\"Failed to upload article: {title}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
